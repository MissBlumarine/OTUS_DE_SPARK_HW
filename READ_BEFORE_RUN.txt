#===========================================================
ПОРЯДОК ДЕЙСТВИЙ:
1. Скачиваем датасет "crime.csv" и справочник кодов "offense_codes.csv"
2. Скачиваем "make_showcase.py"(содержит логику обработки данных) и "make_showcase.sh"(запускающий файл со spark-submit)
3. Делаем настройку запускающего sh файла (нужно указать путь до папки где распложен spark-submit)
4. Выполняем в терминале команду вида: 
./make_showcase.sh "/home/user/Documents/otus_de/spark_hw/crime.csv" "/home/user/Documents/otus_de/spark_hw/offense_codes.csv" "/home/user/Documents/otus_de/spark_hw/fin_showcase"
и ждем-с результата
#===========================================================


#===========================================================
# Исходные данные были получены по адресу:
https://www.kaggle.com/datasets/AnalyzeBoston/crimes-in-boston?resource=download

# Файлы:
- crime.csv
- offense_codes.csv
#===========================================================


#===========================================================
Пояснения по настроке запускающего sh файла:
#!/bin/bash - системная комнда инициализирует запуск терминала (bash)
/opt/spark/bin/spark-submit - здесь нужно поправить путь в соответствии с тем где на запускаемом ПК расположен spark а в частности spark-submit
make_showcase.py - название питоновского скрипта в котором логика приложения
$1 - в данной переменной указываем путь к файлу на диске с датасетом (в нашем случае "crime.csv")
$2 - в данной переменной указываем путь к файлу на диске со словарем (в нашем случае "offense_codes.csv") 
$3 - в данной переменной указываем путь куда будем записывать на диск итоговую витрину
#===========================================================
